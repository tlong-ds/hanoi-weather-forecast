# ================== test_onnx_runtime_gpu.py ==================
import onnxruntime as ort
import numpy as np

# 1ï¸âƒ£ Thiáº¿t láº­p cháº¡y ONNX Runtime báº±ng GPU (CUDA)
providers = [
    ('CUDAExecutionProvider', {'device_id': 0}),  # GPU id = 0
    'CPUExecutionProvider'
]

# 2ï¸âƒ£ Load mÃ´ hÃ¬nh ONNX
session = ort.InferenceSession("temperature.onnx", providers=providers)
print("âœ… ÄÃ£ load mÃ´ hÃ¬nh ONNX thÃ nh cÃ´ng!")

# 3ï¸âƒ£ Xem thÃ´ng tin input/output
input_info = session.get_inputs()[0]
output_info = session.get_outputs()[0]

print(f"ğŸ“¥ Input name: {input_info.name}, shape: {input_info.shape}")
print(f"ğŸ“¤ Output name: {output_info.name}, shape: {output_info.shape}")

# 4ï¸âƒ£ Táº¡o dá»¯ liá»‡u giáº£ (34 feature)
x_test = np.random.rand(1, 34).astype(np.float32)

# 5ï¸âƒ£ Cháº¡y dá»± Ä‘oÃ¡n
y_pred = session.run([output_info.name], {input_info.name: x_test})

print("ğŸ¯ Dá»± Ä‘oÃ¡n tá»« mÃ´ hÃ¬nh ONNX (GPU):", y_pred)
